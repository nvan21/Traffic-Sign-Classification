{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset, random_split\n",
    "import torch\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates the custom image dataset to only get the class ID from the label file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_path: str, transform=transforms):\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "\n",
    "        with open(csv_path, \"r\") as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                # Each row is a dict:\n",
    "                # {\n",
    "                #   'Width': str_value,\n",
    "                #   'Height': str_value,\n",
    "                #   'Roi.X1': str_value,\n",
    "                #   'Roi.Y1': str_value,\n",
    "                #   'Roi.X2': str_value,\n",
    "                #   'Roi.Y2': str_value,\n",
    "                #   'ClassId': str_value,\n",
    "                #   'Path': str_value\n",
    "                # }\n",
    "                self.data.append(row)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.data[idx]\n",
    "\n",
    "        # Extract the image path and label\n",
    "        img_path = os.path.join(\n",
    "            \"/work/flemingc/nvan21/projects/COMS_573_Project/Data\", row[\"Path\"]\n",
    "        )\n",
    "        class_id = int(row[\"ClassId\"])  # convert label to int if necessary\n",
    "\n",
    "        # Load the image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Apply any transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Return image and its class label\n",
    "        return image, class_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "data_paths = [\"./Data/Train\", \"./Data/train_augment\"]\n",
    "batch_size = 512\n",
    "\n",
    "# Make ImageFolder datasets for each augmented image path\n",
    "image_datasets = []\n",
    "for path in data_paths:\n",
    "    image_datasets.append(datasets.ImageFolder(path, transform=transform))\n",
    "\n",
    "# Make a combined training dataset and then split into training and validation\n",
    "combined_dataset = ConcatDataset(image_datasets)\n",
    "train_size = int(0.8 * len(combined_dataset))\n",
    "validate_size = len(combined_dataset) - train_size\n",
    "train_dataset, validate_dataset = random_split(\n",
    "    combined_dataset, [train_size, validate_size]\n",
    ")\n",
    "test_dataset = ImageDataset(csv_path=\"./Data/Test.csv\", transform=transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "validate_loader = DataLoader(\n",
    "    dataset=validate_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_pca(\n",
    "        loader: DataLoader, scaler: StandardScaler, ipca: IncrementalPCA\n",
    "    ):\n",
    "        # Collect all images from the training set for PCA\n",
    "        transformed_list = []\n",
    "        label_list = []\n",
    "        for images, labels in tqdm(loader, \"Fitting PCA for dataset\"):\n",
    "            batch_np = images.view(images.size(0), -1).numpy()\n",
    "            batch_scaled = scaler.transform(batch_np)\n",
    "            batch_pca = ipca.transform(batch_scaled)\n",
    "            transformed_list.append(batch_pca)\n",
    "            label_list.append(labels.numpy())\n",
    "\n",
    "        # Concatenate all batches\n",
    "        X_transformed = np.concatenate(transformed_list, axis=0)\n",
    "        y = np.concatenate(label_list, axis=0)\n",
    "\n",
    "        # Convert to torch tensors\n",
    "        X_transformed_tensor = torch.from_numpy(X_transformed).float()\n",
    "        y_tensor = torch.from_numpy(y).long()\n",
    "\n",
    "        return X_transformed_tensor, y_tensor, X_transformed, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting PCA scaler: 100%|██████████| 123/123 [02:02<00:00,  1.00it/s]\n",
      "Fitting PCA: 100%|██████████| 123/123 [16:25<00:00,  8.01s/it]\n"
     ]
    }
   ],
   "source": [
    "n_components = 150\n",
    "\n",
    "# 1. Incrementally fit the scaler on the entire training set. This scaler will be used to standardize the validation and testing datasets\n",
    "scaler = StandardScaler()\n",
    "for images, _ in tqdm(train_loader, desc=\"Getting PCA scaler\"):\n",
    "    batch_np = images.view(images.size(0), -1).numpy()\n",
    "    scaler.partial_fit(batch_np)\n",
    "\n",
    "# 2. Incrementally fit PCA to avoid memory issues\n",
    "ipca = IncrementalPCA(n_components=n_components)\n",
    "for images, _ in tqdm(train_loader, desc=\"Fitting PCA\"):\n",
    "    batch_np = images.view(images.size(0), -1).numpy()\n",
    "    batch_scaled = scaler.transform(batch_np)\n",
    "    ipca.partial_fit(batch_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting PCA for dataset: 100%|██████████| 123/123 [02:11<00:00,  1.07s/it]\n",
      "Fitting PCA for dataset: 100%|██████████| 31/31 [00:32<00:00,  1.05s/it]\n",
      "Fitting PCA for dataset: 100%|██████████| 25/25 [00:29<00:00,  1.19s/it]\n"
     ]
    }
   ],
   "source": [
    "# 3. Convert each dataset to the PCA version\n",
    "train_pca, train_labels, train_pca_np, train_labels_np = transform_to_pca(\n",
    "    loader=train_loader, scaler=scaler, ipca=ipca\n",
    ")\n",
    "validate_pca, validate_labels, validate_pca_np, validate_labels_np = transform_to_pca(\n",
    "    loader=validate_loader, scaler=scaler, ipca=ipca\n",
    ")\n",
    "test_pca, test_labels, test_pca_np, test_labels_np = transform_to_pca(\n",
    "    loader=test_loader, scaler=scaler, ipca=ipca\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"./Data/pca\", f\"{n_components}\")\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "torch.save(train_pca, os.path.join(path, \"X_train.pt\"))\n",
    "torch.save(train_labels, os.path.join(path, \"y_train.pt\"))\n",
    "torch.save(validate_pca, os.path.join(path, \"X_validate.pt\"))\n",
    "torch.save(validate_labels, os.path.join(path, \"y_validate.pt\"))\n",
    "torch.save(test_pca, os.path.join(path, \"X_test.pt\"))\n",
    "torch.save(test_labels, os.path.join(path, \"y_test.pt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coms_573",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
