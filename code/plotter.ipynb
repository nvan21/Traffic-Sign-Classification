{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Simplified Confusion Matrix Metrics ===\n",
      "    Model  False Positives (FP)  False Negatives (FN)  True Positives (TP)  \\\n",
      "0     SVM                  3381                  3381                 9249   \n",
      "1     KNN                  6251                  6251                 6379   \n",
      "2     CNN                   514                   514                12116   \n",
      "3  RESNET                   230                   230                12400   \n",
      "4     VIT                  1039                  1039                11591   \n",
      "\n",
      "   True Negatives (TN)  \n",
      "0                -3381  \n",
      "1                -6251  \n",
      "2                 -514  \n",
      "3                 -230  \n",
      "4                -1039  \n",
      "\n",
      "=== Model Testing Metrics ===\n",
      "    Model F1 Score Testing Accuracy Inference Time (ms)\n",
      "0     SVM   0.7252           0.7323              0.0005\n",
      "1     KNN   0.5112           0.5051              1.3251\n",
      "2     CNN   0.9590           0.9593              0.9763\n",
      "3  RESNET   0.9816           0.9818              4.5004\n",
      "4     VIT   0.9161           0.9177              3.9087\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the directory containing the models\n",
    "base_dir = \"runs\"\n",
    "models = [\"base_svm\", \"base_knn\", \"base_cnn\", \"base_resnet\", \"base_vit\"]\n",
    "\n",
    "# Define the folder to save images\n",
    "save_dir = \"images\"\n",
    "os.makedirs(save_dir, exist_ok=True)  # Create the folder if it doesn't exist\n",
    "\n",
    "# Initialize storage for metrics\n",
    "metrics = {}\n",
    "\n",
    "# Iterate through models and load data\n",
    "for model in models:\n",
    "    log_path = os.path.join(base_dir, model, \"log.pkl\")\n",
    "    if os.path.exists(log_path):\n",
    "        with open(log_path, \"rb\") as f:\n",
    "            metrics[model] = pickle.load(f)\n",
    "\n",
    "# Ensure all models have been processed\n",
    "if not metrics:\n",
    "    print(\"No log.pkl files found in the specified directories.\")\n",
    "    exit()\n",
    "\n",
    "# Extract metrics for bar graphs and tables\n",
    "inference_times = []\n",
    "testing_accuracies = []\n",
    "f1_scores = []\n",
    "confusion_matrices = []\n",
    "simplified_metrics = []\n",
    "model_names = []\n",
    "\n",
    "# Process metrics for each model\n",
    "for model, data in metrics.items():\n",
    "    model_names.append(model.replace(\"base_\", \"\").upper())\n",
    "    inference_times.append(data.get(\"inference_time\", 0))\n",
    "    testing_accuracies.append(data.get(\"test_accuracy\", 0))\n",
    "    f1_scores.append(data.get(\"f1_score\", 0))\n",
    "\n",
    "# Display simplified confusion matrix metrics\n",
    "df_simplified = pd.DataFrame(simplified_metrics)\n",
    "print(\"\\n=== Simplified Confusion Matrix Metrics ===\")\n",
    "print(df_simplified)\n",
    "\n",
    "# Print testing metrics\n",
    "print(\"\\n=== Model Testing Metrics ===\")\n",
    "df_metrics = pd.DataFrame({\n",
    "    \"Model\": model_names,\n",
    "    \"F1 Score\": [f\"{score:.4f}\" for score in f1_scores],\n",
    "    \"Testing Accuracy\": [f\"{acc:.4f}\" for acc in testing_accuracies],\n",
    "    \"Inference Time (ms)\": [f\"{time * 1000:.4f}\" for time in inference_times]\n",
    "})\n",
    "print(df_metrics)\n",
    "\n",
    "# Plot training accuracy\n",
    "plot_models = [\"base_cnn\", \"base_resnet\", \"base_vit\"]\n",
    "for model in plot_models:\n",
    "    if model in metrics:\n",
    "        data = metrics[model]\n",
    "        epochs = range(1, len(data.get(\"train_accuracy\", [])) + 1)  # Epoch range from 1 to n_epochs\n",
    "\n",
    "        # Plot training and validation accuracy\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(epochs, data.get(\"train_accuracy\", []), label=\"Training Accuracy\", marker=\"o\", linestyle=\"-\")\n",
    "        plt.plot(epochs, data.get(\"val_accuracy\", []), label=\"Validation Accuracy\", marker=\"o\", linestyle=\"--\")\n",
    "        plt.title(f\"Training vs Validation Accuracy: {model.replace('base_', '').upper()}\", fontsize=14, fontweight='bold')\n",
    "        plt.xlabel(\"Epochs\", fontsize=12)\n",
    "        plt.ylabel(\"Accuracy\", fontsize=12)\n",
    "        plt.legend(fontsize=10)\n",
    "        plt.grid(visible=True, linestyle='--', alpha=0.6)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_dir, f\"{model.replace('base_', '').lower()}_accuracy.png\"), dpi=300, format='png')\n",
    "        plt.savefig(os.path.join(save_dir, f\"{model.replace('base_', '').lower()}_accuracy.svg\"), format='svg')\n",
    "        plt.close()\n",
    "\n",
    "        # Plot training and validation loss\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(epochs, data.get(\"train_loss\", []), label=\"Training Loss\", marker=\"s\", linestyle=\"-\")\n",
    "        plt.plot(epochs, data.get(\"val_loss\", []), label=\"Validation Loss\", marker=\"s\", linestyle=\"--\")\n",
    "        plt.title(f\"Training vs Validation Loss: {model.replace('base_', '').upper()}\", fontsize=14, fontweight='bold')\n",
    "        plt.xlabel(\"Epochs\", fontsize=12)\n",
    "        plt.ylabel(\"Loss\", fontsize=12)\n",
    "        plt.legend(fontsize=10)\n",
    "        plt.grid(visible=True, linestyle='--', alpha=0.6)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_dir, f\"{model.replace('base_', '').lower()}_loss.png\"), dpi=300, format='png')\n",
    "        plt.savefig(os.path.join(save_dir, f\"{model.replace('base_', '').lower()}_loss.svg\"), format='svg')\n",
    "        plt.close()\n",
    "\n",
    "# Bar graph for inference time\n",
    "inference_times = [t * 1000 for t in inference_times]  # Convert to ms\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(model_names, inference_times, color='royalblue', edgecolor='black')\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2.0, height, f'{height:.4f} ms', ha='center', va='bottom', fontsize=10)\n",
    "plt.title(\"Inference Time (ms)\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Models\", fontsize=12)\n",
    "plt.ylabel(\"Time (ms)\", fontsize=12)\n",
    "plt.grid(axis=\"y\", linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"inference_time.png\"), dpi=300, format='png')\n",
    "plt.savefig(os.path.join(save_dir, \"inference_time.svg\"), format='svg')\n",
    "plt.close()\n",
    "\n",
    "# Bar graph for testing accuracy\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(model_names, testing_accuracies, color='forestgreen', edgecolor='black')\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2.0, height, f'{height:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "plt.title(\"Testing Accuracy\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Models\", fontsize=12)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0, 1.0)  # Ensure accuracy scale is 0-1\n",
    "plt.grid(axis=\"y\", linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"testing_accuracy.png\"), dpi=300, format='png')\n",
    "plt.savefig(os.path.join(save_dir, \"testing_accuracy.svg\"), format='svg')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionTransformer(\n",
      "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "  (encoder): Encoder(\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): Sequential(\n",
      "      (encoder_layer_0): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_1): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_2): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_3): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_4): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_5): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_6): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_7): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_8): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_9): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_10): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_11): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (heads): Sequential(\n",
      "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Create a Vision Transformer (ViT) b16 model from torchvision.\n",
    "# Set weights='IMAGENET1K_V1' to load pretrained weights, or None for random initialization.\n",
    "model = models.vit_b_16(weights='IMAGENET1K_V1')\n",
    "\n",
    "# Print out the architecture\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "object_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
